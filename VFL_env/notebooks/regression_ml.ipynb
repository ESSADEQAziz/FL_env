{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38131f2e",
   "metadata": {},
   "source": [
    "- synchronize the dimention of the nodes embeddings (dim =4, each) with the input of the server model.\n",
    "- handle the final round to save automaticlly the encoders/weights.\n",
    "- handle the transfert of encoders/weights and preprocessors automaticlly to the server result folder.\n",
    "- match model architecture between trainning and load for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcc7bd",
   "metadata": {},
   "source": [
    "we need to get the entire dataset, and extract the relative vital_signs and lab_results,then align them.(all need to be aligned due to VFL logic) And distibute them across nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = ['../data/node3_chartevents/data.csv','../data/node1_patients/data.csv']\n",
    "original_dataframe = functions.merge_csvs_on_feature(csv_paths=csv_paths,merge_on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = functions.analyze_dataframe(original_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f00d9",
   "metadata": {},
   "source": [
    "- After checking and analysing the features within the dataframe, we choose the feature with less missingness to apply the regression on it, and choose also within the next steps the most related features that can explain it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'respiratory_rate'\n",
    "functions.calculate_mutual_information(original_dataframe,selected_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37446a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.calculate_spearman_correlation(original_dataframe,selected_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a35963",
   "metadata": {},
   "source": [
    "The next step is to test correlation (linear and !linear) between features to apply the specific algorithm to the specific features, but the problem is that features are distributed across nodes within the VFL environment, so to test correlation we need to creat an other system that can handle this step with privacy preserving.(tip used : we gonna based on the HFL correlations tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'respiratory_rate'\n",
    "features = ['respiratory_rate','anchor_year','heart_rate']\n",
    "cleaned_dataframe = functions.prepare_clean_dataset(original_dataframe,features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_= functions.analyze_dataframe(cleaned_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0720271",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate = 0.2\n",
    "pattern = 'MAR'\n",
    "\n",
    "data_with_missingness , original_values = functions.introduce_missingness(df=cleaned_dataframe,feature1=features[0],feature2=features[1],missing_rate=missing_rate,task=\"regression\",pattern=pattern)\n",
    "original_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_= functions.analyze_dataframe(data_with_missingness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= functions.load_ml_model('../server/ml_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee60037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = functions.predict_with_ml_model(data_with_missingness,'ml_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ab41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
