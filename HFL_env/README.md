# Horizontal Federated Learning (HFL) Environment

This module simulates a **Horizontal Federated Learning** (HFL) scenario, where different nodes (e.g., hospitals) possess **similar features** but **different patient cohorts**.

## ğŸ¥ Use Case

Hospitals share the same schema (e.g., blood pressure, vitals) but hold distinct patient records. The objective is to collaboratively impute missing values without centralizing raw patient data.

---

## ğŸ“ Folder Structure

```
HFL_env/
â”œâ”€â”€ test.py                  # Test script for the environment
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration for multi-container setup
â”œâ”€â”€ README.md                # Environment-specific documentation
â”œâ”€â”€ notebooks/               # Jupyter notebooks and utility scripts
â”‚   â”œâ”€â”€ explanatory_variables.ipynb  # Notebook for feature exploration
â”‚   â”œâ”€â”€ regression.ipynb             # Regression analysis notebook
â”‚   â”œâ”€â”€ classification.ipynb         # Classification analysis notebook
â”‚   â”œâ”€â”€ functions.py                 # Python functions used in notebooks
â”‚   â””â”€â”€ __pycache__/                 # Python bytecode cache
â”œâ”€â”€ data/                    # Data for each node and scripts for data processing
â”‚   â”œâ”€â”€ node1/ ... node5/    # Data directories for each node
â”‚   â””â”€â”€ scripts/             # Data extraction and splitting scripts
â”‚       â”œâ”€â”€ extract_vitalSigns_labResults.py
â”‚       â””â”€â”€ split_csv_files.py
â”œâ”€â”€ server/                  # Central server code and results
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies for server
â”‚   â”œâ”€â”€ launch.sh            # Script to launch the server
â”‚   â”œâ”€â”€ Dockerfile           # Dockerfile for server container
â”‚   â”œâ”€â”€ .dockerignore        # Docker ignore file
â”‚   â”œâ”€â”€ logs/                # Server log files (e.g., central_server.log)
â”‚   â”œâ”€â”€ imputation/          # Imputation scripts and results
â”‚       â”œâ”€â”€ machine_learning_regression.py
â”‚       â”œâ”€â”€ deep_learning_regression.py
â”‚       â”œâ”€â”€ deep_learning_classification.py
â”‚       â”œâ”€â”€ machine_learning_classification.py
â”‚       â”œâ”€â”€ functions.py
â”‚       â””â”€â”€ statistical.py
â”‚   â””â”€â”€ results/             # Output results (dl_results, ml_results, stat_results)
â”œâ”€â”€ nodes/                   # Node code and results
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies for nodes
â”‚   â”œâ”€â”€ launch.sh            # Script to launch nodes
â”‚   â”œâ”€â”€ Dockerfile           # Dockerfile for node containers
â”‚   â”œâ”€â”€ .dockerignore        # Docker ignore file
â”‚   â”œâ”€â”€ logs/                # Node log files (e.g., nodes.log)
â”‚   â”œâ”€â”€ imputation/          # Imputation scripts and results (similar to server)
â”‚   â””â”€â”€ results/             # Output results (dl_classification, ml_classification, etc.)
â”œâ”€â”€ certificates/            # SSL certificates for secure communication
â”‚   â”œâ”€â”€ node1/ ... node5/    # Certificates for each node
â”‚   â””â”€â”€ central_server/      # Certificate for the central server
â””â”€â”€ auth_keys/               # Authentication keys for secure access
    â”œâ”€â”€ node1/ ... node5/    # Keys for each node
    â””â”€â”€ central_server/      # Key for the central server
```
## ğŸ” HFL Workflow Overview

The following diagram illustrates the overall workflow of the Horizontal Federated Learning (HFL) environment:
![HFL Workflow](../images/round_hfl.png)
